{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc58bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")  # <-- your project root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "449cee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base sentiment features: (381, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>news_count</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neu</th>\n",
       "      <th>p_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>0.326343</td>\n",
       "      <td>2</td>\n",
       "      <td>0.449530</td>\n",
       "      <td>0.427284</td>\n",
       "      <td>0.123186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-14</td>\n",
       "      <td>-0.274076</td>\n",
       "      <td>3</td>\n",
       "      <td>0.152651</td>\n",
       "      <td>0.420621</td>\n",
       "      <td>0.426728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-15</td>\n",
       "      <td>-0.078525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043608</td>\n",
       "      <td>0.834259</td>\n",
       "      <td>0.122133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-16</td>\n",
       "      <td>0.116737</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140601</td>\n",
       "      <td>0.835536</td>\n",
       "      <td>0.023864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.924714</td>\n",
       "      <td>0.022031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date  sent_score  news_count     p_pos     p_neu     p_neg\n",
       "0   AAPL 2025-08-12    0.326343           2  0.449530  0.427284  0.123186\n",
       "1   AAPL 2025-08-14   -0.274076           3  0.152651  0.420621  0.426728\n",
       "2   AAPL 2025-08-15   -0.078525           1  0.043608  0.834259  0.122133\n",
       "3   AAPL 2025-08-16    0.116737           2  0.140601  0.835536  0.023864\n",
       "4   AAPL 2025-08-17    0.031224           1  0.053255  0.924714  0.022031"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load sentiment score\n",
    "score = pd.read_csv(\"data/processed/sent_headlines_score.csv\", parse_dates=[\"date\"])\n",
    "triplet = pd.read_csv(\"data/processed/sent_headlines_triplet.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "score[\"ticker\"] = score[\"ticker\"].astype(str).str.upper()\n",
    "triplet[\"ticker\"] = triplet[\"ticker\"].astype(str).str.upper()\n",
    "\n",
    "# Aggregate\n",
    "sent_base = (\n",
    "    score.groupby([\"ticker\", \"date\"], as_index=False)\n",
    "         .agg(sent_score=(\"sent_score\", \"mean\"), \n",
    "              news_count=(\"sent_score\", \"count\"))\n",
    "    .merge(\n",
    "        triplet.groupby([\"ticker\",\"date\"], as_index=False)\n",
    "               .agg(p_pos=(\"p_pos\",\"mean\"),\n",
    "                    p_neu=(\"p_neu\",\"mean\"),\n",
    "                    p_neg=(\"p_neg\",\"mean\")),\n",
    "        on=[\"ticker\",\"date\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Base sentiment features:\", sent_base.shape)\n",
    "sent_base.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9f84401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_sentiment_features(df, windows=(3, 5, 10), vol_window=10):\n",
    "    \"\"\"\n",
    "    Compute technical-style features for sentiment data.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns: date, ticker, and sentiment columns (e.g., sent_score, p_pos, p_neu, p_neg)\n",
    "        windows: tuple of window sizes for moving averages\n",
    "        vol_window: window for volatility calculation\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original columns plus sentiment technical features\n",
    "    \"\"\"\n",
    "    out = df.sort_values(['ticker', 'date']).copy()\n",
    "    \n",
    "    # Identify sentiment columns\n",
    "    sent_cols = [c for c in df.columns if c in ['sent_score', 'p_pos', 'p_neu', 'p_neg'] or \n",
    "                 c.startswith(('sent_', 'p_pos', 'p_neu', 'p_neg'))]\n",
    "    \n",
    "    if not sent_cols:\n",
    "        print(\"[warn] No sentiment columns found\")\n",
    "        return out\n",
    "    \n",
    "    # For each sentiment column, compute features\n",
    "    for sent_col in sent_cols:\n",
    "        if sent_col not in out.columns:\n",
    "            continue\n",
    "            \n",
    "        # Group by ticker for time series operations\n",
    "        grouped = out.groupby('ticker')[sent_col]\n",
    "        \n",
    "        # === 1. Moving Averages (SMA & EMA) ===\n",
    "        for w in windows:\n",
    "            # Simple Moving Average\n",
    "            out[f'{sent_col}_sma_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "            \n",
    "            # Exponential Moving Average\n",
    "            out[f'{sent_col}_ema_{w}'] = grouped.transform(lambda x: x.ewm(span=w, adjust=False).mean())\n",
    "            \n",
    "            # Distance from moving average (normalized)\n",
    "            out[f'{sent_col}_dist_sma_{w}'] = out[sent_col] - out[f'{sent_col}_sma_{w}']\n",
    "            out[f'{sent_col}_dist_ema_{w}'] = out[sent_col] - out[f'{sent_col}_ema_{w}']\n",
    "        \n",
    "        # === 2. Momentum & Rate of Change ===\n",
    "        for w in windows:\n",
    "            # Simple momentum (difference)\n",
    "            out[f'{sent_col}_mom_{w}'] = grouped.transform(lambda x: x.diff(w))\n",
    "            \n",
    "            # Rate of change (percentage-like for sentiment)\n",
    "            out[f'{sent_col}_roc_{w}'] = grouped.transform(\n",
    "                lambda x: x.diff(w) / (x.shift(w).abs() + 0.1)  # Add small constant to avoid div by zero\n",
    "            )\n",
    "        \n",
    "        # === 3. Volatility & Standard Deviation ===\n",
    "        # Rolling standard deviation\n",
    "        out[f'{sent_col}_std_{vol_window}'] = grouped.transform(\n",
    "            lambda x: x.rolling(vol_window, min_periods=2).std()\n",
    "        )\n",
    "        \n",
    "        # Coefficient of variation (normalized volatility)\n",
    "        out[f'{sent_col}_cv_{vol_window}'] = out[f'{sent_col}_std_{vol_window}'] / (\n",
    "            out[f'{sent_col}_sma_{vol_window}'].abs() + 0.1\n",
    "        )\n",
    "        \n",
    "        # === 4. Min/Max over windows ===\n",
    "        for w in [5, 10]:\n",
    "            out[f'{sent_col}_max_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).max())\n",
    "            out[f'{sent_col}_min_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).min())\n",
    "            \n",
    "            # Position within range (0 = at min, 1 = at max)\n",
    "            range_val = out[f'{sent_col}_max_{w}'] - out[f'{sent_col}_min_{w}']\n",
    "            out[f'{sent_col}_position_{w}'] = (\n",
    "                (out[sent_col] - out[f'{sent_col}_min_{w}']) / (range_val + 1e-6)\n",
    "            )\n",
    "        \n",
    "        # === 5. Trend Indicators ===\n",
    "        # Simple linear trend (slope over window)\n",
    "        for w in [5, 10]:\n",
    "            out[f'{sent_col}_trend_{w}'] = grouped.transform(\n",
    "                lambda x: x.rolling(w, min_periods=2).apply(\n",
    "                    lambda y: np.polyfit(range(len(y)), y, 1)[0] if len(y) > 1 else 0,\n",
    "                    raw=True\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # === 6. Cumulative metrics ===\n",
    "        # Cumulative sum (overall sentiment accumulation)\n",
    "        out[f'{sent_col}_cumsum'] = grouped.transform('cumsum')\n",
    "        \n",
    "        # Exponentially weighted cumulative sum\n",
    "        out[f'{sent_col}_ewm_cumsum'] = grouped.transform(\n",
    "            lambda x: x.ewm(span=20, adjust=False).mean() * len(x)\n",
    "        )\n",
    "    \n",
    "    # === 7. Cross-sentiment features (if we have triplet) ===\n",
    "    if {'p_pos', 'p_neu', 'p_neg'}.issubset(out.columns):\n",
    "        # Sentiment polarity (pos - neg)\n",
    "        if 'sent_score' not in out.columns:\n",
    "            out['sent_score'] = out['p_pos'] - out['p_neg']\n",
    "        \n",
    "        # Sentiment strength (total non-neutral)\n",
    "        out['sent_strength'] = out['p_pos'] + out['p_neg']\n",
    "        \n",
    "        # Sentiment ratio (pos/neg ratio)\n",
    "        out['sent_ratio'] = out['p_pos'] / (out['p_neg'] + 0.01)\n",
    "        \n",
    "        # Uncertainty (neutral proportion)\n",
    "        out['sent_uncertainty'] = out['p_neu']\n",
    "        \n",
    "        # Dominant sentiment (which is highest)\n",
    "        out['sent_dominant'] = out[['p_pos', 'p_neu', 'p_neg']].idxmax(axis=1).map({\n",
    "            'p_pos': 1, 'p_neu': 0, 'p_neg': -1\n",
    "        })\n",
    "        \n",
    "        # Sentiment consistency (std across triplet)\n",
    "        out['sent_consistency'] = out[['p_pos', 'p_neu', 'p_neg']].std(axis=1)\n",
    "    \n",
    "    # === 8. News volume features (count of articles) ===\n",
    "    # This would need the raw data before aggregation, but we can approximate\n",
    "    # by tracking how sentiment volatility changes (proxy for article count)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def add_news_count_features(headlines_df, windows=(3, 5, 10)):\n",
    "    \"\"\"\n",
    "    Add features based on news article counts per day.\n",
    "    \n",
    "    Args:\n",
    "        headlines_df: Raw headlines with columns: date, ticker, text\n",
    "        windows: Window sizes for moving averages\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with date, ticker, and news count features\n",
    "    \"\"\"\n",
    "    # Count articles per day per ticker\n",
    "    counts = headlines_df.groupby(['date', 'ticker']).size().reset_index(name='news_count')\n",
    "    counts = counts.sort_values(['ticker', 'date'])\n",
    "    \n",
    "    grouped = counts.groupby('ticker')['news_count']\n",
    "    \n",
    "    # Moving averages of news count\n",
    "    for w in windows:\n",
    "        counts[f'news_count_ma_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "        counts[f'news_count_std_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=2).std())\n",
    "    \n",
    "    # News surge indicator (current vs average)\n",
    "    counts['news_surge_5'] = counts['news_count'] / (counts['news_count_ma_5'] + 0.5)\n",
    "    counts['news_surge_10'] = counts['news_count'] / (counts['news_count_ma_10'] + 0.5)\n",
    "    \n",
    "    # Cumulative news count\n",
    "    counts['news_cumcount'] = grouped.transform('cumsum')\n",
    "    \n",
    "    # Days since last news\n",
    "    counts['days_since_news'] = grouped.transform(\n",
    "        lambda x: x.eq(0).cumsum() - x.eq(0).cumsum().where(x.ne(0)).ffill().fillna(0)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92db5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced sentiment: (381, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_dist_sma_{w}'] = out[sent_col] - out[f'{sent_col}_sma_{w}']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_dist_ema_{w}'] = out[sent_col] - out[f'{sent_col}_ema_{w}']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_sma_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_ema_{w}'] = grouped.transform(lambda x: x.ewm(span=w, adjust=False).mean())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_dist_sma_{w}'] = out[sent_col] - out[f'{sent_col}_sma_{w}']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_dist_ema_{w}'] = out[sent_col] - out[f'{sent_col}_ema_{w}']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_mom_{w}'] = grouped.transform(lambda x: x.diff(w))\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_roc_{w}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_mom_{w}'] = grouped.transform(lambda x: x.diff(w))\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_roc_{w}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_mom_{w}'] = grouped.transform(lambda x: x.diff(w))\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_roc_{w}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_std_{vol_window}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_cv_{vol_window}'] = out[f'{sent_col}_std_{vol_window}'] / (\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_max_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).max())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_min_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).min())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_position_{w}'] = (\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_max_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).max())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_min_{w}'] = grouped.transform(lambda x: x.rolling(w, min_periods=1).min())\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_position_{w}'] = (\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_trend_{w}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_trend_{w}'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_cumsum'] = grouped.transform('cumsum')\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f'{sent_col}_ewm_cumsum'] = grouped.transform(\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['sent_strength'] = out['p_pos'] + out['p_neg']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['sent_ratio'] = out['p_pos'] / (out['p_neg'] + 0.01)\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['sent_uncertainty'] = out['p_neu']\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:113: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['sent_dominant'] = out[['p_pos', 'p_neu', 'p_neg']].idxmax(axis=1).map({\n",
      "/var/folders/b_/mlsl2ls12tv6tnhpgltb9vnc0000gn/T/ipykernel_12552/467595299.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out['sent_consistency'] = out[['p_pos', 'p_neu', 'p_neg']].std(axis=1)\n"
     ]
    }
   ],
   "source": [
    "sent_enhanced = compute_sentiment_features(sent_base)\n",
    "print(\"Enhanced sentiment:\", sent_enhanced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2598920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: data/processed/sentiment_features_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "out_path = \"data/processed/sentiment_features_enhanced.csv\"\n",
    "sent_enhanced.to_csv(out_path, index=False)\n",
    "print(\"Saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8655707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged dataset saved.\n",
      "(300, 186)\n"
     ]
    }
   ],
   "source": [
    "tech = pd.read_csv(\"data/processed/merge_T_only_h5.csv\", parse_dates=[\"date\"])\n",
    "tech[\"ticker\"] = tech[\"ticker\"].astype(str).str.upper()\n",
    "\n",
    "df_final = tech.merge(sent_enhanced, on=[\"ticker\",\"date\"], how=\"inner\")\n",
    "\n",
    "df_final.to_csv(\"data/processed/tech_plus_enhanced_sentiment.csv\", index=False)\n",
    "print(\"Final merged dataset saved.\")\n",
    "print(df_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "175f7eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 186)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_enhanced.shape\n",
    "df_final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867d2cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\n",
      "Saved enhanced sentiment to: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter/data/processed/sentiment_features_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# Make sure processed folder exists\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save enhanced sentiment features\n",
    "out_path = Path(\"data/processed/sentiment_features_enhanced.csv\")\n",
    "sent_enhanced.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved enhanced sentiment to:\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adf23252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical shape: (19680, 56)\n",
      "Enhanced sentiment shape: (381, 132)\n",
      "FINAL merged shape: (300, 186)\n",
      "First 10 columns: ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'ret_1d', 'sma_5', 'ema_5']\n",
      "Label columns present: True True\n",
      "Saved final merged DB to: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter/data/processed/merge_T_plus_sent_enhanced_h5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load technical-only file\n",
    "tech = pd.read_csv(\"data/processed/merge_T_only_h5.csv\", parse_dates=[\"date\"])\n",
    "tech[\"ticker\"] = tech[\"ticker\"].astype(str).str.upper()\n",
    "\n",
    "# Load enhanced sentiment we just saved\n",
    "sent_enhanced = pd.read_csv(\"data/processed/sentiment_features_enhanced.csv\", parse_dates=[\"date\"])\n",
    "sent_enhanced[\"ticker\"] = sent_enhanced[\"ticker\"].astype(str).str.upper()\n",
    "\n",
    "print(\"Technical shape:\", tech.shape)\n",
    "print(\"Enhanced sentiment shape:\", sent_enhanced.shape)\n",
    "\n",
    "# Inner join → only dates/tickers where we have both tech and sentiment\n",
    "df_final = tech.merge(sent_enhanced, on=[\"ticker\", \"date\"], how=\"inner\")\n",
    "\n",
    "print(\"FINAL merged shape:\", df_final.shape)\n",
    "print(\"First 10 columns:\", df_final.columns[:10].tolist())\n",
    "print(\"Label columns present:\",\n",
    "      \"y\" in df_final.columns,\n",
    "      \"y_h5\" in df_final.columns)\n",
    "\n",
    "# Save final merged DB\n",
    "final_path = Path(\"data/processed/merge_T_plus_sent_enhanced_h5.csv\")\n",
    "df_final.to_csv(final_path, index=False)\n",
    "print(\"Saved final merged DB to:\", final_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d22a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Python executable:\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Notebook Python executable:\")\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86e49e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_10_15_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-macosx_10_15_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d092b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "print(\"LightGBM version:\", lgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4f1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")  # <-- your project root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22fad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] score: Found 15 rows per ticker-date, aggregating...\n",
      "[warn] triplet: Found 15 rows per ticker-date, aggregating...\n",
      "[warn] embed: Found 15 rows per ticker-date, aggregating...\n",
      "[info] Loaded enhanced sentiment features: 130 features\n",
      "[info] Original sent_enhanced shape: (381, 132)\n",
      "\n",
      "======================================================================\n",
      "FILTERING TO SENTIMENT COVERAGE PERIOD\n",
      "======================================================================\n",
      "  Original tech data: 1968 dates\n",
      "  Sentiment coverage: 82 dates\n",
      "  Filtered tech data: 56 dates\n",
      "  Date range: 2025-08-12 to 2025-10-29\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Using 12 technical features (REDUCED SET):\n",
      "  Features: ret_1d, rsi, sma_20, price_to_sma_20, mom_20, vol_20, bb_width_20, bb_pct_20, macd, macd_signal, vol_ratio, close_position\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "=== Ensemble Model Evaluation ===\n",
      "Model(s): all, Split: chrono, Tune: True\n",
      "======================================================================\n",
      "Class ratio (neg/pos): 0.854\n",
      "Full grid search: ~96 combinations per model\n",
      "[info] Enhanced sentiment MA features: 48\n",
      "[info] Enhanced sentiment momentum features: 32\n",
      "[info] Enhanced sentiment volatility features: 8\n",
      "[info] Enhanced sentiment range features: 24\n",
      "[info] Enhanced sentiment cumulative features: 8\n",
      "[info] Cross-sentiment features: 35\n",
      "[info] News count features: 1\n",
      "[info] Created 48 MA*news_count interaction features\n",
      "\n",
      "[info] Model configurations: 4\n",
      "       1. Technical only (baseline)\n",
      "       2. Technical + Score (simple sentiment)\n",
      "       3. Technical + Triplet (FinBERT probabilities)\n",
      "       4. Technical + Enhanced Sentiment ALL (130 features)\n",
      "\n",
      "======================================================================\n",
      "Model 1: Technical only\n",
      "======================================================================\n",
      "\n",
      "--- XGBoost ---\n",
      "  Train size: 390, Val size: 80, Test size: 90\n",
      "  Train class distribution: [0.48717949 0.51282051]\n",
      "  Val class distribution: [0.4875 0.5125]\n",
      "  Test class distribution: [0.32222222 0.67777778]\n",
      "  Majority baseline (test): 0.6778\n",
      "\n",
      "=== Hyperparameter Tuning ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.5147 with params: (2, 0.01, 300, 5, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5328 with params: (2, 0.01, 300, 10, 0.8, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5372 with params: (2, 0.01, 500, 10, 0.8, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5403 with params: (5, 0.01, 300, 10, 0.8, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters ===\n",
      "  max_depth: 5\n",
      "  learning_rate: 0.01\n",
      "  n_estimators: 300\n",
      "  min_child_weight: 10\n",
      "  subsample: 0.8\n",
      "  colsample_bytree: 0.8\n",
      "  gamma: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5403\n",
      "  [New best XGBoost based on Val AUC: 0.5403]\n",
      "\n",
      "--- LightGBM ---\n",
      "  Train size: 390, Val size: 80, Test size: 90\n",
      "  Train class distribution: [0.48717949 0.51282051]\n",
      "  Val class distribution: [0.4875 0.5125]\n",
      "  Test class distribution: [0.32222222 0.67777778]\n",
      "  Majority baseline (test): 0.6778\n",
      "\n",
      "=== Hyperparameter Tuning (LightGBM) ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.5163 with params: (2, 0.01, 300, 20, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5519 with params: (2, 0.01, 300, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5713 with params: (2, 0.01, 500, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters (LightGBM) ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.01\n",
      "  n_estimators: 500\n",
      "  min_child_samples: 40\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  min_split_gain: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5713\n",
      "\n",
      "--- Random Forest ---\n",
      "  Train size: 390, Val size: 80, Test size: 90\n",
      "  Train class distribution: [0.48717949 0.51282051]\n",
      "  Val class distribution: [0.4875 0.5125]\n",
      "  Test class distribution: [0.32222222 0.67777778]\n",
      "  Majority baseline (test): 0.6778\n",
      "\n",
      "=== Hyperparameter Tuning (Random Forest) ===\n",
      "Searching through 144 combinations...\n",
      "  New best AUC: 0.4653 with params: (100, 5, 5, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.4678 with params: (100, 5, 5, 4, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.4909 with params: (100, 5, 10, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.5047 with params: (200, 10, 5, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.5059 with params: (300, 10, 10, 4, 'sqrt', None)\n",
      "  New best AUC: 0.5078 with params: (300, 15, 5, 4, 'sqrt', None)\n",
      "\n",
      "=== Best Hyperparameters (Random Forest) ===\n",
      "  n_estimators: 300\n",
      "  max_depth: 15\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 4\n",
      "  max_features: sqrt\n",
      "  class_weight: None\n",
      "  Validation AUC: 0.5078\n",
      "\n",
      "======================================================================\n",
      "Model 2: Technical + Score\n",
      "======================================================================\n",
      "\n",
      "--- XGBoost ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.4956 with params: (2, 0.01, 300, 5, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.4970 with params: (2, 0.01, 300, 5, 0.8, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5325 with params: (2, 0.01, 300, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5370 with params: (2, 0.05, 300, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.05\n",
      "  n_estimators: 300\n",
      "  min_child_weight: 10\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  gamma: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5370\n",
      "\n",
      "--- LightGBM ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning (LightGBM) ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.4719 with params: (2, 0.01, 300, 20, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5015 with params: (2, 0.01, 300, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5133 with params: (2, 0.01, 500, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5281 with params: (2, 0.05, 500, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5385 with params: (3, 0.05, 500, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters (LightGBM) ===\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.05\n",
      "  n_estimators: 500\n",
      "  min_child_samples: 40\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  min_split_gain: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5385\n",
      "\n",
      "--- Random Forest ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning (Random Forest) ===\n",
      "Searching through 144 combinations...\n",
      "  New best AUC: 0.4896 with params: (100, 5, 5, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.4926 with params: (100, 5, 5, 2, 'sqrt', None)\n",
      "  New best AUC: 0.5044 with params: (100, 10, 5, 2, 'sqrt', None)\n",
      "  New best AUC: 0.5148 with params: (100, 15, 5, 2, 'sqrt', None)\n",
      "\n",
      "=== Best Hyperparameters (Random Forest) ===\n",
      "  n_estimators: 100\n",
      "  max_depth: 15\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 2\n",
      "  max_features: sqrt\n",
      "  class_weight: None\n",
      "  Validation AUC: 0.5148\n",
      "\n",
      "======================================================================\n",
      "Model 3: Technical + Triplet\n",
      "======================================================================\n",
      "\n",
      "--- XGBoost ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.4956 with params: (2, 0.01, 300, 5, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5118 with params: (2, 0.01, 300, 10, 0.7, 0.8, 0, 0.8543046357615894)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  New best AUC: 0.5118 with params: (2, 0.01, 500, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5222 with params: (2, 0.05, 300, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.5325 with params: (2, 0.05, 500, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.05\n",
      "  n_estimators: 500\n",
      "  min_child_weight: 10\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  gamma: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5325\n",
      "\n",
      "--- LightGBM ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning (LightGBM) ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.5163 with params: (2, 0.01, 300, 20, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters (LightGBM) ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.01\n",
      "  n_estimators: 300\n",
      "  min_child_samples: 20\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  min_split_gain: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.5163\n",
      "\n",
      "--- Random Forest ---\n",
      "  Train size: 186, Val size: 52, Test size: 62\n",
      "  Train class distribution: [0.48924731 0.51075269]\n",
      "  Val class distribution: [0.5 0.5]\n",
      "  Test class distribution: [0.32258065 0.67741935]\n",
      "  Majority baseline (test): 0.6774\n",
      "\n",
      "=== Hyperparameter Tuning (Random Forest) ===\n",
      "Searching through 144 combinations...\n",
      "  New best AUC: 0.4808 with params: (100, 5, 5, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.4867 with params: (100, 5, 5, 4, 'sqrt', None)\n",
      "  New best AUC: 0.4896 with params: (100, 10, 10, 2, 'sqrt', None)\n",
      "  New best AUC: 0.4911 with params: (100, 15, 5, 4, 'sqrt', None)\n",
      "  New best AUC: 0.4956 with params: (100, 15, 10, 2, 'sqrt', None)\n",
      "\n",
      "=== Best Hyperparameters (Random Forest) ===\n",
      "  n_estimators: 100\n",
      "  max_depth: 15\n",
      "  min_samples_split: 10\n",
      "  min_samples_leaf: 2\n",
      "  max_features: sqrt\n",
      "  class_weight: None\n",
      "  Validation AUC: 0.4956\n",
      "\n",
      "======================================================================\n",
      "Model 4: Technical + Enhanced Sentiment (ALL)\n",
      "======================================================================\n",
      "\n",
      "--- XGBoost ---\n",
      "  Train size: 122, Val size: 44, Test size: 50\n",
      "  Train class distribution: [0.52459016 0.47540984]\n",
      "  Val class distribution: [0.43181818 0.56818182]\n",
      "  Test class distribution: [0.34 0.66]\n",
      "  Majority baseline (test): 0.6600\n",
      "\n",
      "=== Hyperparameter Tuning ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.5411 with params: (2, 0.01, 300, 5, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.6105 with params: (2, 0.01, 300, 10, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.01\n",
      "  n_estimators: 300\n",
      "  min_child_weight: 10\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  gamma: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.6105\n",
      "  [New best XGBoost based on Val AUC: 0.6105]\n",
      "\n",
      "--- LightGBM ---\n",
      "  Train size: 122, Val size: 44, Test size: 50\n",
      "  Train class distribution: [0.52459016 0.47540984]\n",
      "  Val class distribution: [0.43181818 0.56818182]\n",
      "  Test class distribution: [0.34 0.66]\n",
      "  Majority baseline (test): 0.6600\n",
      "\n",
      "=== Hyperparameter Tuning (LightGBM) ===\n",
      "Searching through 96 combinations...\n",
      "  New best AUC: 0.5474 with params: (2, 0.01, 300, 20, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "  New best AUC: 0.6042 with params: (2, 0.01, 300, 40, 0.7, 0.8, 0, 0.8543046357615894)\n",
      "\n",
      "=== Best Hyperparameters (LightGBM) ===\n",
      "  max_depth: 2\n",
      "  learning_rate: 0.01\n",
      "  n_estimators: 300\n",
      "  min_child_samples: 40\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.8\n",
      "  min_split_gain: 0\n",
      "  scale_pos_weight: 0.8543046357615894\n",
      "  Validation AUC: 0.6042\n",
      "\n",
      "--- Random Forest ---\n",
      "  Train size: 122, Val size: 44, Test size: 50\n",
      "  Train class distribution: [0.52459016 0.47540984]\n",
      "  Val class distribution: [0.43181818 0.56818182]\n",
      "  Test class distribution: [0.34 0.66]\n",
      "  Majority baseline (test): 0.6600\n",
      "\n",
      "=== Hyperparameter Tuning (Random Forest) ===\n",
      "Searching through 144 combinations...\n",
      "  New best AUC: 0.3747 with params: (100, 5, 5, 2, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.3811 with params: (100, 5, 5, 2, 'sqrt', None)\n",
      "  New best AUC: 0.3874 with params: (100, 5, 5, 2, 'log2', 'balanced')\n",
      "  New best AUC: 0.4042 with params: (100, 5, 5, 2, 'log2', None)\n",
      "  New best AUC: 0.4421 with params: (100, 5, 5, 4, 'sqrt', 'balanced')\n",
      "  New best AUC: 0.4484 with params: (100, 5, 5, 4, 'sqrt', None)\n",
      "  New best AUC: 0.4547 with params: (100, 5, 10, 2, 'log2', None)\n",
      "  New best AUC: 0.4737 with params: (100, 10, 5, 2, 'log2', None)\n",
      "\n",
      "=== Best Hyperparameters (Random Forest) ===\n",
      "  n_estimators: 100\n",
      "  max_depth: 10\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 2\n",
      "  max_features: log2\n",
      "  class_weight: None\n",
      "  Validation AUC: 0.4737\n",
      "\n",
      "======================================================================\n",
      "Best model (by Val AUC): Technical + Enhanced Sentiment (ALL)\n",
      "  Val AUC: 0.6105, Test AUC: 0.6399\n",
      "======================================================================\n",
      "[info] Saved feature importance to reports/best_model_feature_importance.csv\n",
      "[info] Saved best model metadata to reports/best_model_metadata.csv\n",
      "\n",
      "======================================================================\n",
      "=== Final Results Summary ===\n",
      "======================================================================\n",
      "                                    Model  Val Accuracy  Val AUC  Test Accuracy  Test AUC\n",
      "                      XGB: Technical only        0.4875   0.5403         0.4556    0.5574\n",
      "                      LGB: Technical only        0.6125   0.5713         0.5222    0.5342\n",
      "                       RF: Technical only        0.4750   0.5078         0.5444    0.4822\n",
      "                   XGB: Technical + Score        0.5385   0.5370         0.4355    0.4917\n",
      "                   LGB: Technical + Score        0.5577   0.5385         0.4839    0.4286\n",
      "                    RF: Technical + Score        0.5000   0.5148         0.5323    0.5298\n",
      "                 XGB: Technical + Triplet        0.5385   0.5325         0.4516    0.4524\n",
      "                 LGB: Technical + Triplet        0.5385   0.5163         0.4839    0.5565\n",
      "                  RF: Technical + Triplet        0.4808   0.4956         0.4677    0.5071\n",
      "XGB: Technical + Enhanced Sentiment (ALL)        0.4318   0.6105         0.3800    0.6399\n",
      "LGB: Technical + Enhanced Sentiment (ALL)        0.4773   0.6042         0.3800    0.6515\n",
      " RF: Technical + Enhanced Sentiment (ALL)        0.4545   0.4737         0.4600    0.5437\n",
      "======================================================================\n",
      "\n",
      "[info] Saved results to reports/model_comparison_results.csv\n",
      "[info] Saved configurations to reports/model_configurations.csv\n",
      "\n",
      "[info] To analyze best models, run: uv run scripts/analyze_models.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!\"{sys.executable}\" scripts/train_xgboost.py \\\n",
    "    --split chrono \\\n",
    "    --tune \\\n",
    "    --val-size 0.15 \\\n",
    "    --test-size 0.15 \\\n",
    "    --model all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f75e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYZING BEST TREE MODELS\n",
      "======================================================================\n",
      "\n",
      "[1/7] Loading results from reports/model_comparison_results.csv...\n",
      "  Best XGBoost: XGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6399)\n",
      "  Best LightGBM: LGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6515)\n",
      "  Best Random Forest: RF: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.5437)\n",
      "\n",
      "[2/7] Loading data...\n",
      "  Using 94 features (46 technical + 48 sentiment MA)\n",
      "\n",
      "[3/7] Splitting data...\n",
      "  Train: 186, Val: 52, Test: 62\n",
      "\n",
      "[4/7] Training best models...\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "  Training Random Forest...\n",
      "\n",
      "[5/7] Evaluating models...\n",
      "  XGBoost: Test AUC = 0.6548, Acc = 0.5968\n",
      "  LightGBM: Test AUC = 0.5905, Acc = 0.5323\n",
      "  RandomForest: Test AUC = 0.5857, Acc = 0.5645\n",
      "  Saved XGBoost to models/best_xgboost.pkl\n",
      "  Saved LightGBM to models/best_lightgbm.pkl\n",
      "  Saved RandomForest to models/best_randomforest.pkl\n",
      "\n",
      "[6/7] Generating analysis outputs...\n",
      "  [1/4] Saved metrics table\n",
      "[info] Saved ROC curves to reports/model_analysis/roc_curves.png\n",
      "  [2/4] Saved ROC curves\n",
      "[info] Saved training history to reports/model_analysis/training_history.png\n",
      "  [3/4] Saved training history\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_xgboost.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_lightgbm.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_randomforest.png\n",
      "  [4/4] Saved feature importance plots\n",
      "\n",
      "[7/7] Generating summary report...\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📊 Metrics Table:\n",
      "       Model  Train Accuracy  Train AUC  Val Accuracy  Val AUC  Test Accuracy  Test AUC\n",
      "     XGBoost             1.0        1.0        0.5577   0.5261         0.5968    0.6548\n",
      "    LightGBM             1.0        1.0        0.5962   0.5833         0.5323    0.5905\n",
      "RandomForest             1.0        1.0        0.6923   0.6258         0.5645    0.5857\n",
      "\n",
      "\n",
      "📁 Generated Files:\n",
      "  Models:\n",
      "    - models/best_xgboost.pkl\n",
      "    - models/best_lightgbm.pkl\n",
      "    - models/best_randomforest.pkl\n",
      "\n",
      "  Analysis Outputs (in reports/model_analysis/):\n",
      "    - metrics_table.csv\n",
      "    - roc_curves.png\n",
      "    - training_history.png\n",
      "    - feature_importance_xgboost.png + .csv\n",
      "    - feature_importance_lightgbm.png + .csv\n",
      "    - feature_importance_randomforest.png + .csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!\"{sys.executable}\" scripts/analyze_models.py \\\n",
    "    --results-file reports/model_comparison_results.csv \\\n",
    "    --output-dir reports/model_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99dffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Epoch 1: train_loss=0.6859  val_AUC=0.6255\n",
      "Epoch 2: train_loss=0.6670  val_AUC=0.6490\n",
      "Epoch 3: train_loss=0.6562  val_AUC=0.6706\n",
      "Epoch 4: train_loss=0.6440  val_AUC=0.6765\n",
      "Epoch 5: train_loss=0.6327  val_AUC=0.6765\n",
      "Epoch 6: train_loss=0.6221  val_AUC=0.6627\n",
      "Epoch 7: train_loss=0.6083  val_AUC=0.6647\n",
      "Epoch 8: train_loss=0.6011  val_AUC=0.6549\n",
      "Epoch 9: train_loss=0.5900  val_AUC=0.6471\n",
      "Epoch 10: train_loss=0.5769  val_AUC=0.6471\n",
      "Epoch 11: train_loss=0.5700  val_AUC=0.6373\n",
      "Epoch 12: train_loss=0.5523  val_AUC=0.6333\n",
      "Epoch 13: train_loss=0.5412  val_AUC=0.6294\n",
      "Epoch 14: train_loss=0.5257  val_AUC=0.6314\n",
      "Epoch 15: train_loss=0.5181  val_AUC=0.6353\n",
      "Epoch 16: train_loss=0.4965  val_AUC=0.6314\n",
      "Epoch 17: train_loss=0.4895  val_AUC=0.6353\n",
      "Epoch 18: train_loss=0.4696  val_AUC=0.6275\n",
      "Epoch 19: train_loss=0.4522  val_AUC=0.6196\n",
      "Epoch 20: train_loss=0.4409  val_AUC=0.6098\n",
      "Epoch 21: train_loss=0.4254  val_AUC=0.6020\n",
      "Epoch 22: train_loss=0.4104  val_AUC=0.6255\n",
      "Epoch 23: train_loss=0.3890  val_AUC=0.6373\n",
      "Epoch 24: train_loss=0.3763  val_AUC=0.6176\n",
      "Epoch 25: train_loss=0.3586  val_AUC=0.5843\n",
      "Epoch 26: train_loss=0.3478  val_AUC=0.5627\n",
      "Epoch 27: train_loss=0.3322  val_AUC=0.5529\n",
      "Epoch 28: train_loss=0.3161  val_AUC=0.5353\n",
      "Epoch 29: train_loss=0.3006  val_AUC=0.5314\n",
      "Epoch 30: train_loss=0.2909  val_AUC=0.5255\n",
      "\n",
      "=============================\n",
      "LSTM TEST RESULTS\n",
      "=============================\n",
      "Train AUC: 0.9696738022426096  Train ACC: 0.9116022099447514\n",
      "Val   AUC: 0.5254901960784313  Val   ACC: 0.574468085106383\n",
      "Test  AUC: 0.6148648648648649  Test  ACC: 0.7017543859649122\n",
      "Saved LSTM metrics to reports/lstm_results.csv\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Make sure we're at the project root\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# Run your LSTM script\n",
    "!\"{sys.executable}\" scripts/LSTM.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d309409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Val AUC</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.654762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.590476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625817</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.911602</td>\n",
       "      <td>0.969674</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.614865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Train Accuracy  Train AUC  Val Accuracy   Val AUC  \\\n",
       "0       XGBoost        1.000000   1.000000      0.557692  0.526144   \n",
       "1      LightGBM        1.000000   1.000000      0.596154  0.583333   \n",
       "2  RandomForest        1.000000   1.000000      0.692308  0.625817   \n",
       "3          LSTM        0.911602   0.969674      0.574468  0.525490   \n",
       "\n",
       "   Test Accuracy  Test AUC  \n",
       "0       0.596774  0.654762  \n",
       "1       0.532258  0.590476  \n",
       "2       0.564516  0.585714  \n",
       "3       0.701754  0.614865  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trees = pd.read_csv(\"reports/model_analysis/metrics_table.csv\")\n",
    "lstm  = pd.read_csv(\"reports/lstm_results.csv\")\n",
    "\n",
    "combined = pd.concat([trees, lstm], ignore_index=True)\n",
    "combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500944cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(combined[\"Model\"], combined[\"Test AUC\"])\n",
    "plt.ylabel(\"Test AUC\")\n",
    "plt.title(\"Model Comparison – Test AUC\")\n",
    "plt.ylim(0.5, 0.7)\n",
    "for i, v in enumerate(combined[\"Test AUC\"]):\n",
    "    plt.text(i, v + 0.005, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95894dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Epoch 1: train_loss=0.6849  val_AUC=0.4471\n",
      "Epoch 2: train_loss=0.6675  val_AUC=0.5275\n",
      "Epoch 3: train_loss=0.6513  val_AUC=0.5647\n",
      "Epoch 4: train_loss=0.6409  val_AUC=0.5902\n",
      "Epoch 5: train_loss=0.6254  val_AUC=0.5824\n",
      "Epoch 6: train_loss=0.6201  val_AUC=0.5882\n",
      "Epoch 7: train_loss=0.6045  val_AUC=0.5980\n",
      "Epoch 8: train_loss=0.5970  val_AUC=0.6039\n",
      "Epoch 9: train_loss=0.5881  val_AUC=0.5922\n",
      "Epoch 10: train_loss=0.5787  val_AUC=0.5784\n",
      "Epoch 11: train_loss=0.5665  val_AUC=0.5784\n",
      "Epoch 12: train_loss=0.5538  val_AUC=0.5745\n",
      "Epoch 13: train_loss=0.5398  val_AUC=0.5725\n",
      "Epoch 14: train_loss=0.5320  val_AUC=0.5706\n",
      "Epoch 15: train_loss=0.5197  val_AUC=0.5706\n",
      "Epoch 16: train_loss=0.5087  val_AUC=0.5647\n",
      "Epoch 17: train_loss=0.4962  val_AUC=0.5588\n",
      "Epoch 18: train_loss=0.4832  val_AUC=0.5647\n",
      "Epoch 19: train_loss=0.4710  val_AUC=0.5588\n",
      "Epoch 20: train_loss=0.4582  val_AUC=0.5549\n",
      "Epoch 21: train_loss=0.4433  val_AUC=0.5667\n",
      "Epoch 22: train_loss=0.4322  val_AUC=0.5667\n",
      "Epoch 23: train_loss=0.4194  val_AUC=0.5706\n",
      "Epoch 24: train_loss=0.4059  val_AUC=0.5569\n",
      "Epoch 25: train_loss=0.3909  val_AUC=0.5608\n",
      "Epoch 26: train_loss=0.3792  val_AUC=0.5686\n",
      "Epoch 27: train_loss=0.3640  val_AUC=0.5667\n",
      "Epoch 28: train_loss=0.3520  val_AUC=0.5549\n",
      "Epoch 29: train_loss=0.3387  val_AUC=0.5529\n",
      "Epoch 30: train_loss=0.3249  val_AUC=0.5490\n",
      "\n",
      "=============================\n",
      "LSTM RESULTS\n",
      "=============================\n",
      "Train AUC: 0.9692915392456677  Train ACC: 0.9171270718232044\n",
      "Val   AUC: 0.5490196078431373  Val   ACC: 0.5531914893617021\n",
      "Test  AUC: 0.6027027027027028  Test  ACC: 0.6140350877192983\n",
      "Saved metrics to reports/lstm_results.csv\n",
      "Saved test predictions to reports/lstm_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "!\"{sys.executable}\" scripts/LSTM.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3bb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYZING BEST TREE MODELS\n",
      "======================================================================\n",
      "\n",
      "[1/7] Loading results from reports/model_comparison_results.csv...\n",
      "  Best XGBoost: XGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6399)\n",
      "  Best LightGBM: LGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6515)\n",
      "  Best Random Forest: RF: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.5437)\n",
      "\n",
      "[2/7] Loading data...\n",
      "  Using 94 features (46 technical + 48 sentiment MA)\n",
      "\n",
      "[3/7] Splitting data...\n",
      "  Train: 186, Val: 52, Test: 62\n",
      "\n",
      "[4/7] Training best models...\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "  Training Random Forest...\n",
      "\n",
      "[5/7] Evaluating models...\n",
      "  XGBoost: Test AUC = 0.6548, Acc = 0.5968\n",
      "  LightGBM: Test AUC = 0.5905, Acc = 0.5323\n",
      "  RandomForest: Test AUC = 0.5857, Acc = 0.5645\n",
      "  Saved XGBoost to models/best_xgboost.pkl\n",
      "  Saved LightGBM to models/best_lightgbm.pkl\n",
      "  Saved RandomForest to models/best_randomforest.pkl\n",
      "\n",
      "[6/7] Generating analysis outputs...\n",
      "  [1/4] Saved metrics table\n",
      "[info] Added LSTM ROC curve (AUC=0.6027)\n",
      "[info] Saved ROC curves to reports/model_analysis/roc_curves.png\n",
      "  [2/4] Saved ROC curves\n",
      "[info] Saved training history to reports/model_analysis/training_history.png\n",
      "  [3/4] Saved training history\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_xgboost.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_lightgbm.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_randomforest.png\n",
      "  [4/4] Saved feature importance plots\n",
      "\n",
      "[7/7] Generating summary report...\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📊 Metrics Table:\n",
      "       Model  Train Accuracy  Train AUC  Val Accuracy  Val AUC  Test Accuracy  Test AUC\n",
      "     XGBoost             1.0        1.0        0.5577   0.5261         0.5968    0.6548\n",
      "    LightGBM             1.0        1.0        0.5962   0.5833         0.5323    0.5905\n",
      "RandomForest             1.0        1.0        0.6923   0.6258         0.5645    0.5857\n",
      "\n",
      "\n",
      "📁 Generated Files:\n",
      "  Models:\n",
      "    - models/best_xgboost.pkl\n",
      "    - models/best_lightgbm.pkl\n",
      "    - models/best_randomforest.pkl\n",
      "\n",
      "  Analysis Outputs (in reports/model_analysis/):\n",
      "    - metrics_table.csv\n",
      "    - roc_curves.png\n",
      "    - training_history.png\n",
      "    - feature_importance_xgboost.png + .csv\n",
      "    - feature_importance_lightgbm.png + .csv\n",
      "    - feature_importance_randomforest.png + .csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "!\"{sys.executable}\" scripts/analyze_models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01dbce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\n",
      "[info] Using device: cpu\n",
      "\n",
      "[1/4] Loading & preparing data...\n",
      "[info] #tech features       : 12\n",
      "[info] #sentiment MA feats : 48\n",
      "[info] #TOTAL LSTM features: 60\n",
      "[info] Train dates: 2025-08-12 → 2025-10-06 (n=186)\n",
      "[info] Val   dates: 2025-10-07 → 2025-10-16 (n=52)\n",
      "[info] Test  dates: 2025-10-17 → 2025-10-29 (n=62)\n",
      "\n",
      "[2/4] Running LSTM hyperparameter sweep...\n",
      "\n",
      "--- LSTM config: seq_len=3, hidden=32, dropout=0.0, lr=0.001 ---\n",
      "Epoch 01: train_loss=0.7008  val_ACC=0.4800  val_AUC=0.4800\n",
      "Epoch 02: train_loss=0.6877  val_ACC=0.5600  val_AUC=0.5600\n",
      "Epoch 03: train_loss=0.6781  val_ACC=0.8000  val_AUC=0.5800\n",
      "Epoch 04: train_loss=0.6686  val_ACC=0.8400  val_AUC=0.6600\n",
      "Epoch 05: train_loss=0.6595  val_ACC=0.7600  val_AUC=0.6800\n",
      "Epoch 06: train_loss=0.6508  val_ACC=0.7600  val_AUC=0.6700\n",
      "Epoch 07: train_loss=0.6440  val_ACC=0.7600  val_AUC=0.6600\n",
      "Epoch 08: train_loss=0.6343  val_ACC=0.7600  val_AUC=0.6600\n",
      "Epoch 09: train_loss=0.6271  val_ACC=0.7200  val_AUC=0.6800\n",
      "Epoch 10: train_loss=0.6192  val_ACC=0.7200  val_AUC=0.6800\n",
      "[info] Early stopping after 10 epochs (no val AUC improvement).\n",
      "  -> Config result: val_AUC=0.6800, test_AUC=0.3322\n",
      "\n",
      "--- LSTM config: seq_len=5, hidden=32, dropout=0.2, lr=0.001 ---\n",
      "Epoch 01: train_loss=0.6771  val_ACC=0.4000  val_AUC=0.7619\n",
      "Epoch 02: train_loss=0.6627  val_ACC=0.7000  val_AUC=0.8571\n",
      "Epoch 03: train_loss=0.6589  val_ACC=0.7000  val_AUC=0.9048\n",
      "Epoch 04: train_loss=0.6368  val_ACC=0.8000  val_AUC=0.8571\n",
      "Epoch 05: train_loss=0.6284  val_ACC=0.9000  val_AUC=0.8571\n",
      "Epoch 06: train_loss=0.6240  val_ACC=0.7000  val_AUC=0.8571\n",
      "Epoch 07: train_loss=0.6082  val_ACC=0.7000  val_AUC=0.8571\n",
      "Epoch 08: train_loss=0.6101  val_ACC=0.7000  val_AUC=0.8571\n",
      "[info] Early stopping after 8 epochs (no val AUC improvement).\n",
      "  -> Config result: val_AUC=0.8571, test_AUC=0.4861\n",
      "\n",
      "--- LSTM config: seq_len=5, hidden=64, dropout=0.2, lr=0.001 ---\n",
      "Epoch 01: train_loss=0.6896  val_ACC=0.8000  val_AUC=1.0000\n",
      "Epoch 02: train_loss=0.6743  val_ACC=0.8000  val_AUC=0.9048\n",
      "Epoch 03: train_loss=0.6509  val_ACC=0.8000  val_AUC=0.9048\n",
      "Epoch 04: train_loss=0.6488  val_ACC=0.7000  val_AUC=0.9048\n",
      "Epoch 05: train_loss=0.6195  val_ACC=0.7000  val_AUC=0.8571\n",
      "Epoch 06: train_loss=0.6106  val_ACC=0.7000  val_AUC=0.8571\n",
      "[info] Early stopping after 6 epochs (no val AUC improvement).\n",
      "  -> Config result: val_AUC=0.8571, test_AUC=0.5833\n",
      "\n",
      "--- LSTM config: seq_len=7, hidden=64, dropout=0.2, lr=0.0005 ---\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 01: train_loss=0.7057  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 02: train_loss=0.6988  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 03: train_loss=0.6868  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 04: train_loss=0.6772  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 05: train_loss=0.6726  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 06: train_loss=0.6629  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 07: train_loss=0.6566  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 08: train_loss=0.6482  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 09: train_loss=0.6399  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 10: train_loss=0.6348  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 11: train_loss=0.6257  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 12: train_loss=0.6185  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 13: train_loss=0.6075  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 14: train_loss=0.5998  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 15: train_loss=0.5934  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 16: train_loss=0.5908  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 17: train_loss=0.5882  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 18: train_loss=0.5795  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 19: train_loss=0.5696  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 20: train_loss=0.5722  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 21: train_loss=0.5617  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 22: train_loss=0.5494  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 23: train_loss=0.5454  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 24: train_loss=0.5378  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 25: train_loss=0.5292  val_ACC=0.0000  val_AUC=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 26: train_loss=0.5226  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 27: train_loss=0.5101  val_ACC=0.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 28: train_loss=0.5060  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 29: train_loss=0.5054  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 30: train_loss=0.4896  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 31: train_loss=0.4791  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 32: train_loss=0.4694  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 33: train_loss=0.4647  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 34: train_loss=0.4652  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 35: train_loss=0.4528  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 36: train_loss=0.4424  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 37: train_loss=0.4344  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 38: train_loss=0.4335  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 39: train_loss=0.4265  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "Epoch 40: train_loss=0.4233  val_ACC=1.0000  val_AUC=nan\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "  -> Config result: val_AUC=nan, test_AUC=1.0000\n",
      "\n",
      "======================================================================\n",
      "Best LSTM config based on validation AUC:\n",
      "  seq_len=5, hidden=32, dropout=0.2, lr=0.001\n",
      "  Train: ACC=0.7014, AUC=0.7543\n",
      "  Val:   ACC=0.7000,   AUC=0.8571\n",
      "  Test:  ACC=0.4118,  AUC=0.4861\n",
      "======================================================================\n",
      "\n",
      "[3/4] Saving LSTM metrics...\n",
      "[info] Saved metrics table to reports/lstm_results.csv\n",
      "[info] Saved best-config test predictions to reports/lstm_test_predictions.csv\n",
      "\n",
      "[4/4] Done ✅\n",
      "======================================================================\n",
      "ANALYZING BEST MODELS (Trees + LSTM)\n",
      "======================================================================\n",
      "\n",
      "[1/7] Loading tree comparison results from reports/model_comparison_results.csv...\n",
      "  Best XGBoost: XGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6399)\n",
      "  Best LightGBM: LGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6515)\n",
      "  Best Random Forest: RF: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.5437)\n",
      "\n",
      "[2/7] Loading data...\n",
      "  Using 94 features (46 technical + 48 sentiment MA)\n",
      "\n",
      "[3/7] Splitting data (chronological)...\n",
      "  Train: 186, Val: 52, Test: 62\n",
      "\n",
      "[4/7] Training tree models with best hyperparameters...\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "  Training RandomForest...\n",
      "\n",
      "[5/7] Evaluating tree models...\n",
      "  XGBoost: Test AUC = 0.6548, Acc = 0.5968\n",
      "  LightGBM: Test AUC = 0.5905, Acc = 0.5323\n",
      "  RandomForest: Test AUC = 0.5857, Acc = 0.5645\n",
      "  Saved XGBoost to models/best_xgboost.pkl\n",
      "  Saved LightGBM to models/best_lightgbm.pkl\n",
      "  Saved RandomForest to models/best_randomforest.pkl\n",
      "\n",
      "[6/7] Generating analysis outputs...\n",
      "  [info] Appended LSTM metrics from reports/lstm_results.csv\n",
      "  [1/4] Saved metrics table (trees + LSTM if available)\n",
      "[info] Added LSTM ROC curve (AUC=0.4861)\n",
      "[info] Saved ROC curves to reports/model_analysis/roc_curves.png\n",
      "  [2/4] Saved ROC curves\n",
      "[info] Saved training history to reports/model_analysis/training_history.png\n",
      "  [3/4] Saved training history\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_xgboost.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_lightgbm.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_randomforest.png\n",
      "  [4/4] Saved feature importance plots\n",
      "\n",
      "[7/7] Generating summary report...\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE - SUMMARY (Trees + LSTM)\n",
      "======================================================================\n",
      "\n",
      "📊 Metrics Table:\n",
      "       Model  Train Accuracy  Train AUC  Val Accuracy  Val AUC  Test Accuracy  Test AUC  seq_len  hidden_units  dropout     lr\n",
      "     XGBoost          1.0000     1.0000        0.5577   0.5261         0.5968    0.6548      NaN           NaN      NaN    NaN\n",
      "    LightGBM          1.0000     1.0000        0.5962   0.5833         0.5323    0.5905      NaN           NaN      NaN    NaN\n",
      "RandomForest          1.0000     1.0000        0.6923   0.6258         0.5645    0.5857      NaN           NaN      NaN    NaN\n",
      "        LSTM          0.6688     0.7726        0.7200   0.6800         0.5429    0.3322      3.0          32.0      0.0 0.0010\n",
      "        LSTM          0.7014     0.7543        0.7000   0.8571         0.4118    0.4861      5.0          32.0      0.2 0.0010\n",
      "        LSTM          0.6806     0.7302        0.7000   0.8571         0.6471    0.5833      5.0          64.0      0.2 0.0010\n",
      "        LSTM          0.8047     0.9084        1.0000      NaN         0.8000    1.0000      7.0          64.0      0.2 0.0005\n",
      "\n",
      "\n",
      "📁 Generated Files:\n",
      "  Models (trees):\n",
      "    - models/best_xgboost.pkl\n",
      "    - models/best_lightgbm.pkl\n",
      "    - models/best_randomforest.pkl\n",
      "\n",
      "  Analysis Outputs (in reports/model_analysis/):\n",
      "    - metrics_table.csv          (trees + LSTM row if available)\n",
      "    - roc_curves.png             (trees + LSTM curve if available)\n",
      "    - training_history.png       (trees only)\n",
      "    - feature_importance_xgboost.png + .csv\n",
      "    - feature_importance_lightgbm.png + .csv\n",
      "    - feature_importance_randomforest.png + .csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# 1) Train & tune LSTM (this will write reports/lstm_results.csv + lstm_test_predictions.csv)\n",
    "!\"{sys.executable}\" scripts/LSTM_copy.py\n",
    "\n",
    "# 2) Re-run model analysis (trees + tuned LSTM)\n",
    "!\"{sys.executable}\" scripts/analyze_models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ef83ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\n",
      "/Users/rosaliemassein/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Epoch 1: train_loss=0.6856  val_AUC=0.4706\n",
      "Epoch 2: train_loss=0.6671  val_AUC=0.5353\n",
      "Epoch 3: train_loss=0.6525  val_AUC=0.6118\n",
      "Epoch 4: train_loss=0.6415  val_AUC=0.6569\n",
      "Epoch 5: train_loss=0.6279  val_AUC=0.6569\n",
      "Epoch 6: train_loss=0.6203  val_AUC=0.6431\n",
      "Epoch 7: train_loss=0.6091  val_AUC=0.6314\n",
      "Epoch 8: train_loss=0.5980  val_AUC=0.6216\n",
      "Epoch 9: train_loss=0.5859  val_AUC=0.6196\n",
      "Epoch 10: train_loss=0.5769  val_AUC=0.6000\n",
      "Epoch 11: train_loss=0.5620  val_AUC=0.5843\n",
      "Epoch 12: train_loss=0.5535  val_AUC=0.5804\n",
      "Epoch 13: train_loss=0.5396  val_AUC=0.5569\n",
      "Epoch 14: train_loss=0.5304  val_AUC=0.5569\n",
      "Epoch 15: train_loss=0.5172  val_AUC=0.5510\n",
      "Epoch 16: train_loss=0.5066  val_AUC=0.5529\n",
      "Epoch 17: train_loss=0.4921  val_AUC=0.5490\n",
      "Epoch 18: train_loss=0.4753  val_AUC=0.5412\n",
      "Epoch 19: train_loss=0.4632  val_AUC=0.5314\n",
      "Epoch 20: train_loss=0.4508  val_AUC=0.5216\n",
      "Epoch 21: train_loss=0.4347  val_AUC=0.5353\n",
      "Epoch 22: train_loss=0.4169  val_AUC=0.5275\n",
      "Epoch 23: train_loss=0.4038  val_AUC=0.5235\n",
      "Epoch 24: train_loss=0.3856  val_AUC=0.5157\n",
      "Epoch 25: train_loss=0.3704  val_AUC=0.5157\n",
      "Epoch 26: train_loss=0.3574  val_AUC=0.5078\n",
      "Epoch 27: train_loss=0.3409  val_AUC=0.4863\n",
      "Epoch 28: train_loss=0.3300  val_AUC=0.4941\n",
      "Epoch 29: train_loss=0.3123  val_AUC=0.4843\n",
      "Epoch 30: train_loss=0.2967  val_AUC=0.4765\n",
      "\n",
      "=============================\n",
      "LSTM RESULTS\n",
      "=============================\n",
      "Train AUC: 0.9655963302752294  Train ACC: 0.9226519337016574\n",
      "Val   AUC: 0.4764705882352941  Val   ACC: 0.5319148936170213\n",
      "Test  AUC: 0.6405405405405405  Test  ACC: 0.6140350877192983\n",
      "Saved metrics to reports/lstm_results.csv\n",
      "Saved test predictions to reports/lstm_test_predictions.csv\n",
      "======================================================================\n",
      "ANALYZING BEST MODELS (Trees + LSTM)\n",
      "======================================================================\n",
      "\n",
      "[1/7] Loading tree comparison results from reports/model_comparison_results.csv...\n",
      "  Best XGBoost: XGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6399)\n",
      "  Best LightGBM: LGB: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.6515)\n",
      "  Best Random Forest: RF: Technical + Enhanced Sentiment (ALL) (Test AUC: 0.5437)\n",
      "\n",
      "[2/7] Loading data...\n",
      "  Using 94 features (46 technical + 48 sentiment MA)\n",
      "\n",
      "[3/7] Splitting data (chronological)...\n",
      "  Train: 186, Val: 52, Test: 62\n",
      "\n",
      "[4/7] Training tree models with best hyperparameters...\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "  Training RandomForest...\n",
      "\n",
      "[5/7] Evaluating tree models...\n",
      "  XGBoost: Test AUC = 0.6548, Acc = 0.5968\n",
      "  LightGBM: Test AUC = 0.5905, Acc = 0.5323\n",
      "  RandomForest: Test AUC = 0.5857, Acc = 0.5645\n",
      "  Saved XGBoost to models/best_xgboost.pkl\n",
      "  Saved LightGBM to models/best_lightgbm.pkl\n",
      "  Saved RandomForest to models/best_randomforest.pkl\n",
      "\n",
      "[6/7] Generating analysis outputs...\n",
      "  [info] Appended LSTM metrics from reports/lstm_results.csv\n",
      "  [1/4] Saved metrics table (trees + LSTM if available)\n",
      "[info] Added LSTM ROC curve (AUC=0.6405)\n",
      "[info] Saved ROC curves to reports/model_analysis/roc_curves.png\n",
      "  [2/4] Saved ROC curves\n",
      "[info] Saved training history to reports/model_analysis/training_history.png\n",
      "  [3/4] Saved training history\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_xgboost.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_lightgbm.png\n",
      "[info] Saved feature importance to reports/model_analysis/feature_importance_randomforest.png\n",
      "  [4/4] Saved feature importance plots\n",
      "\n",
      "[7/7] Generating summary report...\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE - SUMMARY (Trees + LSTM)\n",
      "======================================================================\n",
      "\n",
      "📊 Metrics Table:\n",
      "       Model  Train Accuracy  Train AUC  Val Accuracy  Val AUC  Test Accuracy  Test AUC\n",
      "     XGBoost          1.0000     1.0000        0.5577   0.5261         0.5968    0.6548\n",
      "    LightGBM          1.0000     1.0000        0.5962   0.5833         0.5323    0.5905\n",
      "RandomForest          1.0000     1.0000        0.6923   0.6258         0.5645    0.5857\n",
      "        LSTM          0.9227     0.9656        0.5319   0.4765         0.6140    0.6405\n",
      "\n",
      "\n",
      "📁 Generated Files:\n",
      "  Models (trees):\n",
      "    - models/best_xgboost.pkl\n",
      "    - models/best_lightgbm.pkl\n",
      "    - models/best_randomforest.pkl\n",
      "\n",
      "  Analysis Outputs (in reports/model_analysis/):\n",
      "    - metrics_table.csv          (trees + LSTM row if available)\n",
      "    - roc_curves.png             (trees + LSTM curve if available)\n",
      "    - training_history.png       (trees only)\n",
      "    - feature_importance_xgboost.png + .csv\n",
      "    - feature_importance_lightgbm.png + .csv\n",
      "    - feature_importance_randomforest.png + .csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir(\"/Users/rosaliemassein/Documents/stanford/Autumn 2025/CS229/Project/ML-Stock-Prediction-main/cs229-sentiment-vs-tech-starter\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# 1) Train & tune LSTM (this will write reports/lstm_results.csv + lstm_test_predictions.csv)\n",
    "!\"{sys.executable}\" scripts/LSTM_copy.py\n",
    "\n",
    "# 2) Re-run model analysis (trees + tuned LSTM)\n",
    "!\"{sys.executable}\" scripts/analyze_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9cd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs229)",
   "language": "python",
   "name": "cs229"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
