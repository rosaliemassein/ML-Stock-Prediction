{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "CUT = pd.Timestamp(\"2025-10-15\")\n",
    "\n",
    "def eval_file(path, extra_feature_cols=None, label_col=\"y_h5\"):\n",
    "    df = pd.read_csv(path, parse_dates=[\"date\"]).sort_values([\"ticker\",\"date\"])\n",
    "    # Colonnes techniques de base (ajuste selon ce que tu as)\n",
    "    tech_cols = [c for c in df.columns if c not in [\"date\",\"ticker\",\"y\",\"y_h5\",\"future_return_5d\",\"close\",\"open\",\"high\",\"low\",\"volume\",\"sent_score\",\"p_pos\",\"p_neu\",\"p_neg\",\"event_weight\",\"sent_x_weight\",\"p_pos_x_weight\",\"p_neu_x_weight\",\"p_neg_x_weight\"]]\n",
    "    # Garder des features techniques plausibles (exemple simple)\n",
    "    tech_keep = [c for c in tech_cols if any(k in c.lower() for k in [\"sma\",\"mom\",\"rsi\",\"vol\",\"ret_1d\"])] or tech_cols\n",
    "\n",
    "    feat_cols = tech_keep.copy()\n",
    "    if extra_feature_cols:\n",
    "        feat_cols += [c for c in extra_feature_cols if c in df.columns]\n",
    "\n",
    "    df = df.dropna(subset=feat_cols+[label_col]).copy()\n",
    "\n",
    "    train = df[df[\"date\"] < CUT]\n",
    "    test  = df[df[\"date\"] >= CUT]\n",
    "\n",
    "    if len(train) == 0 or len(test) == 0:\n",
    "        raise ValueError(f\"Empty split for {path}. Check CUT date.\")\n",
    "\n",
    "    Xtr = train[feat_cols].values\n",
    "    ytr = train[label_col].values\n",
    "    Xte = test[feat_cols].values\n",
    "    yte = test[label_col].values\n",
    "\n",
    "    # standardisation train-only\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(Xtr)\n",
    "    Xte = scaler.transform(Xte)\n",
    "\n",
    "    # logistique régularisée (évite singularités)\n",
    "    clf = LogisticRegression(\n",
    "        C=1.0,           # tu peux tuner (0.1, 1, 10)\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,\n",
    "        class_weight=None # ou 'balanced' si classes très déséquilibrées\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "    proba = clf.predict_proba(Xte)[:,1]\n",
    "    pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"rows_train\": len(train),\n",
    "        \"rows_test\": len(test),\n",
    "        \"pos_train\": float(ytr.mean()),\n",
    "        \"pos_test\":  float(yte.mean()),\n",
    "        \"AUC\": roc_auc_score(yte, proba),\n",
    "        \"ACC\": accuracy_score(yte, pred)\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "rows.append((\"T-only\",     eval_file(\"data/processed/merge_T_only_h5.csv\",                extra_feature_cols=[])))\n",
    "rows.append((\"T+Score\",    eval_file(\"data/processed/merge_TS_score_h5.csv\",              extra_feature_cols=[\"sent_score\",\"event_weight\",\"sent_x_weight\"])))\n",
    "rows.append((\"T+Triplet\",  eval_file(\"data/processed/merge_TS_triplet_h5.csv\",            extra_feature_cols=[\"p_pos\",\"p_neu\",\"p_neg\",\"event_weight\",\"p_pos_x_weight\",\"p_neu_x_weight\",\"p_neg_x_weight\"])))\n",
    "\n",
    "pd.DataFrame(\n",
    "    [(name, m[\"rows_train\"], m[\"rows_test\"], m[\"pos_train\"], m[\"pos_test\"], m[\"AUC\"], m[\"ACC\"]) for name,m in rows],\n",
    "    columns=[\"dataset\",\"train_rows\",\"test_rows\",\"train_pos\",\"test_pos\",\"AUC\",\"ACC\"]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
